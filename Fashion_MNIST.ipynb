{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Fashion-MNIST.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QtAG7cOZoPQ"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import os \n",
        "import matplotlib.pyplot as plt \n",
        "import datetime \n",
        "import tensorflow as tf  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnNVM9jsZoPV"
      },
      "source": [
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXU8K96jZoPW"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Gb34ggvbZoPW"
      },
      "source": [
        "train = np.load('image-classification-fashion-mnist/train.npy')\n",
        "validation = np.load('image-classification-fashion-mnist/validation.npy')\n",
        "test = np.load('image-classification-fashion-mnist/test.npy')\n",
        "train_ans = pd.read_csv('image-classification-fashion-mnist/train.csv')\n",
        "validation_ans = pd.read_csv('image-classification-fashion-mnist/validation.csv')\n",
        "test_ans = pd.read_csv('image-classification-fashion-mnist/sample_submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3AdBN1dZoPX"
      },
      "source": [
        "# Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-4txUH0ZoPX"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(train)\n",
        "train = scaler.transform(train)\n",
        "validation = scaler.transform(validation)\n",
        "test = scaler.transform(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26KlgfwPZoPX"
      },
      "source": [
        "# Imply to different models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJ2aNROVZoPY"
      },
      "source": [
        "#SVM \n",
        "from sklearn import svm\n",
        "start = datetime.datetime.now()\n",
        "clf = svm.SVC(kernel = 'rbf')\n",
        "clf.fit(train,train_ans['class'])\n",
        "#time used for training the model\n",
        "time_used = datetime.datetime.now() - start\n",
        "print(\"time_usage_for_training:\", time_used)\n",
        "pred_train = clf.predict(train)\n",
        "pred_val = clf.predict(validation)\n",
        "pred_test = clf.predict(test)\n",
        "#accuracy, precision, F1 score, recall \n",
        "precision_train = precision_score(train_ans['class'], pred_train, average = \"micro\")\n",
        "recall_train = recall_score(train_ans['class'], pred_train, average = \"micro\")\n",
        "accuracy_train = accuracy_score(train_ans['class'], pred_train)\n",
        "f1score_train = f1_score(train_ans['class'], pred_train, average = \"micro\")\n",
        "precision_val = precision_score(validation_ans['class'], pred_val, average = \"micro\")\n",
        "recall_val = recall_score(validation_ans['class'], pred_val, average = \"micro\")\n",
        "accuracy_val = accuracy_score(validation_ans['class'], pred_val)\n",
        "f1score_val = f1_score(validation_ans['class'], pred_val, average = \"micro\")\n",
        "precision_test = precision_score(test_ans['class'], pred_test, average = \"micro\")\n",
        "recall_test = recall_score(test_ans['class'], pred_test, average = \"micro\")\n",
        "accuracy_test = accuracy_score(test_ans['class'], pred_test)\n",
        "f1score_test = f1_score(test_ans['class'], pred_test, average = \"micro\")\n",
        "print(\"preison:\", precision_train)\n",
        "print(\"recall:\", recall_train)\n",
        "print(\"accuracy:\", accuracy_train)\n",
        "print(\"f1_score:\", f1score_train)\n",
        "print(\"preison:\", precision_val)\n",
        "print(\"recall:\", recall_val)\n",
        "print(\"accuracy:\", accuracy_val)\n",
        "print(\"f1_score:\", f1score_val)\n",
        "print(\"preison:\", precision_test)\n",
        "print(\"recall:\", recall_test)\n",
        "print(\"accuracy:\", accuracy_test)\n",
        "print(\"f1_score:\", f1score_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSO5UDxeZoPZ"
      },
      "source": [
        "#knn\n",
        "from sklearn.neighbors import KNeighborsClassifier \n",
        "start = datetime.datetime.now()\n",
        "neigh = KNeighborsClassifier(n_neighbors=5)\n",
        "neigh.fit(train,train_ans['class'])\n",
        "#time used for training the model\n",
        "time_used = datetime.datetime.now() - start\n",
        "print(\"time_usage_for_training:\", time_used)\n",
        "pred_train = neigh.predict(train)\n",
        "pred_val = neigh.predict(validation)\n",
        "pred_test = neigh.predict(test)\n",
        "#accuracy, precision, F1 score, recall \n",
        "precision_train = precision_score(train_ans['class'], pred_train, average = \"micro\")\n",
        "recall_train = recall_score(train_ans['class'], pred_train, average = \"micro\")\n",
        "accuracy_train = accuracy_score(train_ans['class'], pred_train)\n",
        "f1score_train = f1_score(train_ans['class'], pred_train, average = \"micro\")\n",
        "precision_val = precision_score(validation_ans['class'], pred_val, average = \"micro\")\n",
        "recall_val = recall_score(validation_ans['class'], pred_val, average = \"micro\")\n",
        "accuracy_val = accuracy_score(validation_ans['class'], pred_val)\n",
        "f1score_val = f1_score(validation_ans['class'], pred_val, average = \"micro\")\n",
        "precision_test = precision_score(test_ans['class'], pred_test, average = \"micro\")\n",
        "recall_test = recall_score(test_ans['class'], pred_test, average = \"micro\")\n",
        "accuracy_test = accuracy_score(test_ans['class'], pred_test)\n",
        "f1score_test = f1_score(test_ans['class'], pred_test, average = \"micro\")\n",
        "print(\"preison:\", precision_train)\n",
        "print(\"recall:\", recall_train)\n",
        "print(\"accuracy:\", accuracy_train)\n",
        "print(\"f1_score:\", f1score_train)\n",
        "print(\"preison:\", precision_val)\n",
        "print(\"recall:\", recall_val)\n",
        "print(\"accuracy:\", accuracy_val)\n",
        "print(\"f1_score:\", f1score_val)\n",
        "print(\"preison:\", precision_test)\n",
        "print(\"recall:\", recall_test)\n",
        "print(\"accuracy:\", accuracy_test)\n",
        "print(\"f1_score:\", f1score_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ls2SIcy1ZoPc"
      },
      "source": [
        "#Logistic regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "start = datetime.datetime.now()\n",
        "clf = LogisticRegression(max_iter = 1000)\n",
        "# for i,j in zip(range(0,50,10), range(10,60,10)):\n",
        "#     clf.fit(train[i:j],train_ans['class'][i:j])\n",
        "clf.fit(train,train_ans['class'])\n",
        "#time used for training the model\n",
        "time_used = datetime.datetime.now() - start\n",
        "print(\"time_usage_for_training:\", time_used)    \n",
        "pred_train = clf.predict(train)\n",
        "pred_val = clf.predict(validation)\n",
        "pred_test = clf.predict(test)\n",
        "#accuracy, precision, F1 score, recall \n",
        "precision_train = precision_score(train_ans['class'], pred_train, average = \"micro\")\n",
        "recall_train = recall_score(train_ans['class'], pred_train, average = \"micro\")\n",
        "accuracy_train = accuracy_score(train_ans['class'], pred_train)\n",
        "f1score_train = f1_score(train_ans['class'], pred_train, average = \"micro\")\n",
        "precision_val = precision_score(validation_ans['class'], pred_val, average = \"micro\")\n",
        "recall_val = recall_score(validation_ans['class'], pred_val, average = \"micro\")\n",
        "accuracy_val = accuracy_score(validation_ans['class'], pred_val)\n",
        "f1score_val = f1_score(validation_ans['class'], pred_val, average = \"micro\")\n",
        "precision_test = precision_score(test_ans['class'], pred_test, average = \"micro\")\n",
        "recall_test = recall_score(test_ans['class'], pred_test, average = \"micro\")\n",
        "accuracy_test = accuracy_score(test_ans['class'], pred_test)\n",
        "f1score_test = f1_score(test_ans['class'], pred_test, average = \"micro\")\n",
        "print(\"preison:\", precision_train)\n",
        "print(\"recall:\", recall_train)\n",
        "print(\"accuracy:\", accuracy_train)\n",
        "print(\"f1_score:\", f1score_train)\n",
        "print(\"preison:\", precision_val)\n",
        "print(\"recall:\", recall_val)\n",
        "print(\"accuracy:\", accuracy_val)\n",
        "print(\"f1_score:\", f1score_val)\n",
        "print(\"preison:\", precision_test)\n",
        "print(\"recall:\", recall_test)\n",
        "print(\"accuracy:\", accuracy_test)\n",
        "print(\"f1_score:\", f1score_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XP495KPLZoPd"
      },
      "source": [
        "#Decision tree classification \n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "start = datetime.datetime.now()\n",
        "clf = DecisionTreeClassifier(max_depth=8)\n",
        "clf.fit(train, train_ans['class'])\n",
        "#time used for training the model\n",
        "time_used = datetime.datetime.now() - start\n",
        "print(\"time_usage_for_training:\", time_used)  \n",
        "pred_train = clf.predict(train)\n",
        "pred_val = clf.predict(validation)\n",
        "pred_test = clf.predict(test)\n",
        "#accuracy, precision, F1 score, recall \n",
        "precision_train = precision_score(train_ans['class'], pred_train, average = \"micro\")\n",
        "recall_train = recall_score(train_ans['class'], pred_train, average = \"micro\")\n",
        "accuracy_train = accuracy_score(train_ans['class'], pred_train)\n",
        "f1score_train = f1_score(train_ans['class'], pred_train, average = \"micro\")\n",
        "precision_val = precision_score(validation_ans['class'], pred_val, average = \"micro\")\n",
        "recall_val = recall_score(validation_ans['class'], pred_val, average = \"micro\")\n",
        "accuracy_val = accuracy_score(validation_ans['class'], pred_val)\n",
        "f1score_val = f1_score(validation_ans['class'], pred_val, average = \"micro\")\n",
        "precision_test = precision_score(test_ans['class'], pred_test, average = \"micro\")\n",
        "recall_test = recall_score(test_ans['class'], pred_test, average = \"micro\")\n",
        "accuracy_test = accuracy_score(test_ans['class'], pred_test)\n",
        "f1score_test = f1_score(test_ans['class'], pred_test, average = \"micro\")\n",
        "print(\"preison:\", precision_train)\n",
        "print(\"recall:\", recall_train)\n",
        "print(\"accuracy:\", accuracy_train)\n",
        "print(\"f1_score:\", f1score_train)\n",
        "print(\"preison:\", precision_val)\n",
        "print(\"recall:\", recall_val)\n",
        "print(\"accuracy:\", accuracy_val)\n",
        "print(\"f1_score:\", f1score_val)\n",
        "print(\"preison:\", precision_test)\n",
        "print(\"recall:\", recall_test)\n",
        "print(\"accuracy:\", accuracy_test)\n",
        "print(\"f1_score:\", f1score_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyenIMqpZoPe"
      },
      "source": [
        "#Random forest classification \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "start = datetime.datetime.now()\n",
        "clf = RandomForestClassifier()\n",
        "clf.fit(train, train_ans['class'])\n",
        "#time used for training the model\n",
        "time_used = datetime.datetime.now() - start\n",
        "print(\"time_usage_for_training:\", time_used)  \n",
        "pred_train = clf.predict(train)\n",
        "pred_val = clf.predict(validation)\n",
        "pred_test = clf.predict(test)\n",
        "#accuracy, precision, F1 score, recall \n",
        "precision_train = precision_score(train_ans['class'], pred_train, average = \"micro\")\n",
        "recall_train = recall_score(train_ans['class'], pred_train, average = \"micro\")\n",
        "accuracy_train = accuracy_score(train_ans['class'], pred_train)\n",
        "f1score_train = f1_score(train_ans['class'], pred_train, average = \"micro\")\n",
        "precision_val = precision_score(validation_ans['class'], pred_val, average = \"micro\")\n",
        "recall_val = recall_score(validation_ans['class'], pred_val, average = \"micro\")\n",
        "accuracy_val = accuracy_score(validation_ans['class'], pred_val)\n",
        "f1score_val = f1_score(validation_ans['class'], pred_val, average = \"micro\")\n",
        "precision_test = precision_score(test_ans['class'], pred_test, average = \"micro\")\n",
        "recall_test = recall_score(test_ans['class'], pred_test, average = \"micro\")\n",
        "accuracy_test = accuracy_score(test_ans['class'], pred_test)\n",
        "f1score_test = f1_score(test_ans['class'], pred_test, average = \"micro\")\n",
        "print(\"preison:\", precision_train)\n",
        "print(\"recall:\", recall_train)\n",
        "print(\"accuracy:\", accuracy_train)\n",
        "print(\"f1_score:\", f1score_train)\n",
        "print(\"preison:\", precision_val)\n",
        "print(\"recall:\", recall_val)\n",
        "print(\"accuracy:\", accuracy_val)\n",
        "print(\"f1_score:\", f1score_val)\n",
        "print(\"preison:\", precision_test)\n",
        "print(\"recall:\", recall_test)\n",
        "print(\"accuracy:\", accuracy_test)\n",
        "print(\"f1_score:\", f1score_test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}